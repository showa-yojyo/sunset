---
title: 316 日目（曇りのち雨のち曇り）快挙
---

スーリオンのレベルを 66 まで上げてカンストを確認。案外短時間で終わる。
次にクロエと入れ替えて、やはりレベル 66 まで上げて今日のゲームを終了とする。
ウルファールと夕一はそれぞれ 96, 79 になった。夕一についてはたぶん途中で投げる。

9:05 起床。洗濯をしたいと思っていたが雨か。かまわず洗濯する。
納豆とおにぎりを食す。携帯電話でニュースと天気予報をチェックして洗濯物を窓際に干す。
窓際に干すのは天気に関係ない。

外出して八広図書館へ移動。朝刊（産経、東京）を読んで入館。キャレルに着席。

* いつもの更新
* 久しぶりに危険なファイルをダウンロード
* Scrapy の LinkExtractor の概念を理解する。なるほどこれは有用だ。
* [【髭の打ち込み】ダライアス　CAPTAIN NEO / COSMIC AIR WAY　30年前　中学生の打ち込み事情 - YouTube](https://www.youtube.com/watch?v=LTdADRPnOFg):
  あるコメントへの髭先生の回答が熱い。

昼過ぎ退館。雨がまともに降っているので傘をさす。イトーヨーカドー曳舟店で体温をチェック。

12:45 曳舟の部屋に戻る。PC を戻しておやつ休憩など。キーボードの A の効きが悪い。

14:45 ブレイク。昼寝する。16:10 起き上がる。雨が降らないらしいので傘を持たずに出る。
スカイツリータウンに立ち寄った後に押上駅バス停で待つ。
携帯電話をチェックすると、先週の会社から面談日程の連絡がある。返信。
あと GitHub からまたブログのビルドエラー通知。そんなはずはないだろう。

16:55 タイトー F ステーションオリナス錦糸町店。

MJ にログインするとおとといの幻球バトル東風の成績発表だ。
入賞は確信していたが、望外のベスト 8 をゲット。長いことやってきたが第何位のついた称号を獲得するのは初めて。
久々にうれしい思いをする。これはほんとうにうれしい。画面内のアバター画像の枠に出てくるから見栄えもいい。
報酬の幻球 12 個のおかげで、幻球乱舞の負債は完全返済。

そして今日のプロ卓東風戦の成績は……。

```text
【SCORE】
合計SCORE:-162.7

【最終段位】
四人打ち段位:魔神 幻球:9

【3/8の最新8試合の履歴】
1st|-----*--
2nd|------*-
3rd|-**----*
4th|*--**---
old         new

【順位】
1位回数:1(10.00%)
2位回数:1(10.00%)
3位回数:5(50.00%)
4位回数:3(30.00%)
平均順位:3.00

プレイ局数:49局

【打ち筋】
アガリ率:12.24%(6/49)
平均アガリ翻:2.83翻
平均アガリ巡目:12.17巡
振込み率:8.16%(4/49)

【3/8の最高役】
最高役のデータがありません。最高役は、跳満以上のアガリが対象となります。
```

ビートマニア。ARENA モードでレベル 11 の TOMOSUKE 先生の Max なんとかみたいな曲をクリア。

19:50 カスミオリナス錦糸町店。288 円。

* オクラ茄子丼
* ブラックチョコ

20:15 ビッグエー墨田業平店。412 円。今日はレジ後が妙に混んでいる。

* 絹豆腐
* お肉屋さんのハンバーグ
* 大きなおむすび梅と昆布
* カレーパン
* コッペパンジャム＆マーガリン
* ドデカイラーメンチキンラジ

20:30 曳舟の部屋に戻る。入浴して 21:00 出る。就労活動報告書を書き足して PC の電源を入れる。
豆腐を食いながら帳簿、日記。そして晩飯＆麻雀の練習。

22:15 テザリングで情報収集して戻ってくる。昼前に習得した Scrapy のリンク抽出機能をまとめておく。

22:40 ゲームに逃避する。[ウルファールのサンプルゲーム with DTC][bshf21b] をやる。
次のレベル上げは DTC 組から二人まとめてやる。上がり方が鈍い夕一は常に表に出しておく。

22:50 ホーリィと、少し遅れてウルフのレベルを 66 でカンストさせる。
このパーティー、経験値上げが地味にキツイ。ニワトリ以外ゴールドアクスを装備できないのが痛い。
面白いのは、ラストダンジョンのポイズンジャイアントとアムルアムトのコンビとの戦い方が全然変わるということ。
巨人を魅惑か凍結させて、ネコを先に倒すのがしっくりくる。ウルフは二刀流でがんばる。

ロズモンドとビビアンと入れ替える。夕一は巻物を併用してレベル 80 に到達。

## Scrapy Note

クラス `LinkExtractor` 周辺に関するあれこれを記す。

* `scrapy.linkextractors.lxmlhtml.LxmlLinkExtractor` が真のクラス名だが、
  `from scrapy.linkextractors import LinkExtractor` で使える。
* チュートリアルでは crawler クラスの `rules` に組み込んでいるが、
  `Reponse` オブジェクトさえ手許にあればこれ単体で利用できる。
* コンストラクターとメソッド `.extract_links()` だけ理解すれば十分だ。
* コンストラクター
  * 引数のすべてがキーワード引数。デフォルトでもまともに機能する。
    その場合はページ中にある `<a>`, `<area>` の集合を抽出するように振る舞うようだ。
    引数 `allow`, `deny` を必要に応じて指定すれば事足りそうだ。
  * 引数 `restrict_xpaths`, `restrict_css` を利用すれば、あるノード範囲にあるリンクを選択できるだろう。
  * 引数 `restrict_text` はリンクテキストを制限する。私の場合は `"東風戦"` と指定するのだろう。
  * 引数 `tags` を使うと `a` 以外にもリンクを拾える。すぐに思いつくのは `img` だ。しかしこれには `href` はない。
  * そこで引数 `attrs` を指定すればいい。`attrs=('src',)` とすればいいだろう。
* メソッド `.extract_links()`
  * `Response` オブジェクトを受け取り、`scrapy.link.Link` オブジェクトのリストを返す。
    ここで、クラス `Link` はドキュメント中のリンクを表す要素を表現するものだ。
    ドキュメントがないので IPython などでインターフェイスを調べる。
* クラス `Link`
  * 基本的には構造体のようなものと思っていい。憶えておけばいいのは次のものだけ：
    * `.url`: もちろんリンクの URL を表す文字列だ。コメントでは絶対 URL だと言っている。
    * `.text`: リンク要素の開始終了タグに囲まれているリンクテキスト文字列。
    * `.fragment`: URL の `&num;` から後の文字列を保持する。

[bshf21b]: https://wodifes.net/game/show/446
