---
title: 335 日目（晴れ）トップが一度もなくても気にならなくなってきた
---

[ウルファールのサンプルゲーム with DTC][bshf21b] の続き。バッドレディーズ戦からラスボスまでストレートに行けない。
メルホース戦をわざわざ選んだのにエディの武装を間違えたのがよくない。炎っぽいのが無難。

いったん 7:30 に起きるが、休みの日につき微妙な時間帯だ。二度寝。

しばらくして起床。納豆とロールパンを頬張って PC を持って外出。

9:20 八広図書館。朝刊（産経、東京）を読んで入館。学校側キャレルへ。

* [&#x23;616 雷電 Raiden BGM ギターメドレー - YouTube](https://www.youtube.com/watch?v=uWulFwezVtA): ダウンロードして MP3 リストに。
* [女流プロと麻雀YouTuberによるチーム戦。優勝の行方は。【上野PLACE】 - YouTube](https://www.youtube.com/watch?v=b2_SIAG_yMw):
  とにかくにぎやかな回。堀内プロはチップでも何でも強い。
* 23 区図書館の新装オープンなどをチェック。4 館ある？
* スクレイピング実践
* [リンクの冒険「神殿」 - YouTube](https://www.youtube.com/watch?v=OMiJxDfv3bM)
* [リンクの冒険 神殿BGM 打込みZelda II: The Adventure of Link "temple" copy - YouTube](https://www.youtube.com/watch?v=l-4XW-bv6ig)
* [[MSX][MGSDRV] リンクの冒険 『神殿』のテーマ - YouTube](https://www.youtube.com/watch?v=HHdEFFNSZG8)

その他、結局 YouTube で時間つぶしになる。昔のドラクエのキャンセル歩行駆使系ビデオが面白い。

12:10 退館。イトーヨーカドー曳舟店で体温チェック。

12:45 曳舟の部屋に戻る。PC を戻しておやつ休憩。麻雀の練習をしてからファイル整理。
今日ダウンロードしたファイル群はネタ系が多くて退屈しない。今日は昼寝をせずに乗り切れた。

夕方、外出前に郵便着信。年金と福祉事務所から。
前者はこの前さんざん体使わされた手続きがようやく正常に終わった通知。
後者は年度初めの各種お便りなど。緊急のものはなくて安心する。

外出してスカイツリータウンへ移動。トイレに行くのに人混みがすごくて遠回り。
用を足したらバス停へ移動。錦糸公園前まで移動。

16:50 タイトー F ステーションオリナス錦糸町店。
MJ 幻球乱舞東風。今回もボコボコにされる予感があったので、期待せずに打つ。

```text
合計スコア 不明
平均スコア 不明

平均順位 2.81 着
トップ 0 回
二着 6 回
三着 7 回
ラス 3 回

アガリ率 ???% (???)
アガリ飜平均 ???
アガリ巡目平均 ??? 巡
振り込み率 ???% (???)
```

携帯電話を手にしていたのに、成績画面を間違えてスキップしてしまったので正確なデータは不明。
着順だけは記憶している。閉店間際まで 9 クレも遊んでしまった。

気分転換にビートマニア STEP UP をワンプレイ。無難にクリアできる曲しかやらない。

20:50 カスミオリナス錦糸町店。490 円。クーポン使用。

* 十勝 4 種チーズソース入りメンチカツ弁当
* 野菜ジュース (900)
* ブラックチョコ

21:15 ビッグエー墨田業平店。578 円。考え事をしていて買い過ぎる。

* 絹豆腐
* 明太のり弁当
* ふっくらおむすび梅
* テーブルロール (5)
* ハムマヨパン
* 元祖たこ焼き亭
* コッペパンホイップ＆チョコ

以前白飯を買ったのにおにぎりを買うという似たボケを犯したことがあるが、弁当を買ったのを忘れて弁当を買うというのはひどい。
私の脳はおそらく何かまずいことになっているだろう。

21:20 曳舟の部屋に戻る。入浴して 22:00 出る。さっきの手紙を確認。
PC の電源を入れて帳簿をつける。豆腐を平らげてから晩飯。
麻雀の練習。練習でも何か勝ち切れない展開が多い。

22:35 テザリングをやる。22:55 調べ物に復帰。[Scrapy] のアイテムローダーの節を読み込む。
文章が長いので一時間では要約し切れない。内容を理解するのは比較的容易。
これは演習が必要だな。一つの response から一つの item しか得られないように見えるが、それは違うはずだ。

そろそろ一日が終わる。

## Scrapy Note

### Item Loaders

アイテムローダーはスクレイプしたアイテムを増やしていくことに対する便利な仕組みを供与する。
アイテムが直接的に増やせるものであっても、スクレイプ過程からそれらを増やすためのもっと便利な API をアイテムローダーは供与する。

アイテムはスクレイプしたデータの入れ物を、アイテムローダーは入れ物の中身を増やす仕組みをそれぞれ与える。

#### Using Item Loaders to populate items

アイテムローダーの基本的な利用法を記す。
まずは `ItemLoader` のオブジェクトを生成する。このときに何かアイテムを与える場合と与えない場合がある。
後者の場合にはコンストラクター内部で属性 `ItemLoader.default_item_class` が指定するアイテムクラスを使う。

アイテムローダーを生成したら、値を集めてそれに突っ込む。ふつうはセレクターによる。
同じアイテムフィールドに対して一つ以上の値を追加できる。
というのも、アイテムローダーは後で適切な加工関数を使って、その値の集まりを join する方法を知ることになる。

ドキュメントにあるコードを引用して、スパイダークラスでのよくあるアイテムローダーの利用例コードを見ていく：

```python
import scrapy
from scrapy.loader import ItemLoader
from myproject.items import Product

class MySpider(scrapy.Spider):

    def parse(self, response):
        l = ItemLoader(item=Product(), response=response)
        l.add_xpath('name', '//div[@class="product_name"]')
        l.add_xpath('name', '//div[@class="product_title"]')
        l.add_xpath('price', '//p[@id="price"]')
        l.add_css('stock', 'p#stock')
        l.add_value('last_updated', 'today')
        return l.load_item()
```

* クラス `Product` は自作クラスである。ドキュメントを参照（このデモコードからフィールド定義を想像できると思う）。
* クラス `ItemLoader` のオブジェクトを生成。
  * ここではアイテムのテンプレを明示的に与えている。
  * キーワード引数 `response` や `selector` を指定して、スクレイプ対象を与える。
* ローダーのメソッド `.add_xpath()` や `.add_css()` により、スクレイプアイテムのフィールドの抽出仕様をローダーに populate していく。
  先述のように、単一のフィールドに対してロード方法が複数あっても構わない。
* ローダーのメソッド `.add_value()` ではスクレイプ対象から値を取らせず、フィールドに好きな値を直接指定する。
* ローダーのメソッド `.load_item()` でクラス `Product` のオブジェクトを生成することが容易に想像できる。

#### Working with dataclass items

サードパーティー製パッケージ `dataclasses` の `@dataclass` を利用してアイテムクラスを定義している場合には、
フィールドを定義する際に関数 `field()` をデフォルト引数を指定する手間を要する（ドキュメントを参照）。

#### Input and Output processors

アイテムローダーには、アイテムフィールドそれぞれに対して入力プロセッサーと出力プロセッサーがそれぞれ一つずつある。
先程のデモコードで解説する。

* 最初の `add_xpath()` がデータを抽出し、フィールド `name` の入力プロセッサーにそれを渡す。
  この入力処理結果は収集されてローダー内部のどこかにいったん保持される。アイテムに対しては結果をまだ割り当てない。
* 次の `add_xpath()` がデータを抽出し、同じ入力プロセッサーにそれを渡す。
  この入力処理結果は、ローダー内部のどこかに保持されている収集リストに追加する。
* このような処理がフィールドごと `load_item()` 呼び出しまでに行われる。
* 最終的収集データは `name` などのフィールドごとに、対応する出力プロセッサーに渡される。
  この出力処理結果は、アイテム内の `name` などのフィールドそれぞれに代入される値だ。

プロセッサーは単に callable オブジェクトであるということを憶えておくといい。
型さえ合えばどんな関数でも入力プロセッサーや出力プロセッサーとして使えるのだ。

#### Declaring Item Loaders

アイテムローダーを定義する手順を記す。

クラス `ItemLoader` のサブクラスという形式で定義する。一例はドキュメントにあるとおり。

* サードパーティー製パッケージのサブモジュール `itemloaders.processors` が提供する
  `TakeFirst`, `MapCompose`, `Join` といった構成要素（おそらくクラス）を利用する。
* ローダーには `_in`, `_out` で終わる名前のフィールド対を定義する。
  アンダースコアの前の部分はアイテムフィールドの名前とする。
* オプショナルに、既定の入力・出力プロセッサーを与えることもできる。
  それぞれ `default_input_processor`, `default_out_processor` とする。


#### Declaring Input and Output Processors

入力プロセッサーまたは出力プロセッサーを宣言するのはローダークラスでもできるし、
入力プロセッサーを宣言するのはそのやり方で行うのが普通だ。
しかし、アイテムフィールドのメタデータでプロセッサーを指定することもできる。
ドキュメントのサンプルコードを一部抜粋するとこうだ：

```python

class Product(scrapy.Item):
    name = scrapy.Field(
        input_processor=MapCompose(remove_tags),
        output_processor=Join(),
    )
    price = scrapy.Field(
        input_processor=MapCompose(remove_tags, filter_price),
        output_processor=TakeFirst(),
    )
```

プロセッサーの優先度は次の通り：

1. ローダーフィールド固有の属性、つまり `xxxx_in`, `xxxx_out` のようなフィールド
2. フィールドメタデータ、つまりキー `input_processor` と `output_processor` に対応する値
3. ローダーの既定値、つまり `.default_input_processor()` と `.default_output_processor()`

[bshf21b]: https://wodifes.net/game/show/446
[scrapy]: https://scrapy.org/
