---
title: 323 日目（晴れ）完全攻略
---

テザリングで PC からファイルをアップロードしたいが、できない。原因不明。
携帯電話からのインターネット接続はできていて、PC からも ping くらいは通じるという状態。
PC 上のブラウザーでのインターネット接続ができていない。これはわからない。

寝る。夜中に二度ほどトイレのために睡眠を中断する。冷えるのか。

9:05 起床。またトイレ。朝食を取り次第 PC を持って外出する。あとハガキを送りたいのでペンと一緒に持つ。

コンビニに道草して朝刊が出ていないのを確認。週プレをチェックして退店。何も買わないで悪い。

9:45 八広図書館。ダイレクトに入館する。窓際キャレルへ。

* ファイル同期。やっと GitHub にファイルがコピーできた。
* ファイル更新は特に発生せず。
* [Scrapy][scrapy] の演習。またぞろ明文化しづらいコツを発見してしまった。
* [リアルなファミコン音源による打ち込み方法&#x23;2 ドラクエ序曲ベタ打ちまで【初心者向け・MML】 - YouTube](https://www.youtube.com/watch?v=12K3VYm8vrg):
  この内容で初心者向けというのが良心的だ。ブラボー。
* 合間に月刊文藝春秋 2021.4 号を読む。

12:30 打ち切る。イトーヨーカドー曳舟店に行って体温測定。今月半分のデータがとれた。
勤務先のハガキにシールを貼って京島一丁目郵便局のポストに放り込む。

13:00 曳舟の部屋に戻る。PC を戻しておやつ休憩。麻雀の練習。
さっきの演習でダウンロードしたファイルをチェック。思ったより少ない。

15:10 タイムカード代わりに使わされている携帯電話を充電するのを忘れた。眠くなる前に外出。
スカイツリータウンに移動。トイレと書店に行く。

押上駅前からバスに乗って錦糸町駅前へ移動。

16:15 時間があるのでハローワーク錦糸町に行って求人検索をする。4 社ほどの求人票を印刷して出る。

ブックオフに移動。芹沢のハゲの第二巻があるので少しだけチェック。
スペリオール掲載回を一部読み逃しているものを確認。芹沢の進路を説明する、物語の急所の回だった。

16:50 タイトー F ステーションオリナス錦糸町店。

MJ プロ卓東風戦。イベントで入賞してからひどい成績になっているが、何か関連があるのか？
麻将連合の清水英二プロが対面に同卓。好調なときに同卓したいものだ。
気をつけていたつもりだが、なまじいい手に育ってしまったら止まらない。
プロがリーチした巡目でよくわからぬ牌をツモってきて、押したら絵に描いたような三面張に一発放銃。

```text
【SCORE】
合計SCORE:-192.4

【最終段位】
四人打ち段位:魔神 幻球:4

【3/15の最新8試合の履歴】

1st|------*-
2nd|*-*-----
3rd|---*-*--
4th|-*--*--*
old         new

【順位】
1位回数:1(10.00%)
2位回数:2(20.00%)
3位回数:2(20.00%)
4位回数:5(50.00%)
平均順位:3.10

プレイ局数:47局

【打ち筋】
アガリ率:8.51%(4/47)
平均アガリ翻:3.50翻
平均アガリ巡目:13.25巡
振込み率:12.77%(6/47)

【3/15の最高役】
・跳満
```

跳満以上をアガると最高役リストが生成されるが、そこのスクレイピングコードを書いていない。
リンク先和了手牌画像のダウンロードまで自動化したい。

19:45 カスミオリナス錦糸町店。455 円。

* オクラ茄子丼
* ささみチーズフライ (3)
* ブラックチョコ
* ライス

20:10 ビッグエー墨田業平店。262 円。

* 絹豆腐
* コロッケドッグ
* ジャージーミルククリームリング
* ポテコうましお

20:25 曳舟の部屋に戻る。今日は先に食事。PC 前に座って豆腐をなめつつ帳簿。
晩飯＆麻雀の練習。練習だとおかしなことはそうそう起こらない。不思議だ。

テザリングでインターネットを見る。それから [Scrapy][scrapy] の学習。セレクターはだいぶわかっているが。

22:05 入浴。22:35 出る。Scrapy の調査の続き。

23:15 [Scrapy][scrapy] を中断する。[ウルファールのサンプルゲーム with DTC][bshf21b] に進む。
最後はロズモンドとビビアンでファルコ戦か。無理だと思うがもう少し粘る。

23:45 ファルコを倒す。超持久戦。戦闘だけで 30 分かかる。たぶんこのゲーム史上最長の戦闘時間になった。

![ロズモンドとビビアンの二人だけでファルコ撃破]({{ "/assets/images/bshf21b-boss04.jpg" | relative_url }})

## Scrapy Note

### Selectors

#### セレクターの使い方

`Response` オブジェクトの `.selector` を経由してメソッド `.css()` や `.xpath()` で
CSS セレクターや XPath を指定することでノードを得るというのが基本形となる。
これらを選択メソッドと呼ぶことにする。

`Response` オブジェクトに対して同名の選択メソッドを呼び出すこともできる。これらは本来のメソッドへの単なるショートカットだ。

`Selector` オブジェクトを直接生成することもできる。セレクターの練習のときにそうするかもしれない。

* コンストラクターの引数は HTML テキストを表す `str` オブジェクトか `HtmlResponse` オブジェクトとなる。

選択メソッドの戻り値は `SelectorList` オブジェクトだ。
これに対する次の操作をしっかりと習得すること：

* `.get()`
* `.getall()`
* `.attrib`

CSS セレクターには [Scrapy][scrapy] による次の拡張仕様が付与されている。

* `::text` はテキストノードを選択する。
* `::attr(name)` は属性ノードを選択する。

選択メソッドの戻り値はセレクターのリストであるので、その要素に対しても選択メソッドを呼び出せることに注意すること。

要素ノードの属性を選択する手段が複数あることに注意すること。

メソッド `.re()` を利用することで `Selector` オブジェクトに対して正規表現でフィルターすることができる。
選択メソッドで抽出し切れないときにこれを併用するのだろう。

#### XPath の使い方

[Scrapy][scrapy] に限らず有用なので XPath の基本は別途学習しておくこと。
[Scrapy][scrapy] をいじるついでに習得してもいい。注意点：

* 絶対パスと相対パスの区別に気をつける（ファイルパスのそれ以上に）。
* 場合によっては `.css()` を併用することになる。CSS クラスが複数ある要素ノードが絡むなど。
* これは [Scrapy][scrapy] とは関係なく成り立つのだが、`//node[1]` と `(//node)[1]` は異なる。
* XPath 関数 `text()` を用いると選択メソッドに対する `.getall()` の戻り値が `str` のリストになる。
* XPath 関数 `string()` を入れ子要素に対して使うと文字列解析が楽になる場合がある。
* XPath 関数 `contains()` も使いやすい。

XPath 式で変数を埋め込むことができる。次のコード片はドキュメントより引用した：

```python
response.xpath('//div[@id=$val]/a/text()', val='images')
response.xpath('//div[count(a)=$cnt]/@id', cnt=5)
```

RSS など、構文解析する対象によっては名前空間外しを必要とする。
アクティブなセレクターに対して `.remove_namespaces()` を呼び出してから `.xpath()` を呼ばないとまともに値を返さない。

その他発展的なトピックは省略。まずは基本を習得するのだ。

#### 組み込みセレクター

* `Selector`: 応答の内容の特定の部分を選択するための機能
  * `.attrib` はノードの属性を表す `dict` オブジェクト。
  * `.xpath()`, `.css()` は `SelectorList` を返す。
  * `.get()` はノードを `str` で返す。
  * `.getall()` はノードを `str` で表したものからなるリストを返す。
  * `.re()` は正規表現を適用して `str` のリストを返す。
  * `.remove_namespaces()` はあまり使いたくないが存在は憶えておくこと。
* `SelectorList`: 組み込み `list` のサブクラスに `Selector` で見てきたメソッドのほとんどを加えたもの

[bshf21b]: https://wodifes.net/game/show/446
[scrapy]: https://scrapy.org/
